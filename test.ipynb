{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run start\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import argparse\n",
    "import time\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "print(\"run start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parser():\n",
    "  # arguments preparation\n",
    "  parser = argparse.ArgumentParser(description=\"Style Transfer\")\n",
    "\n",
    "  # required arguments\n",
    "  parser.add_argument('content_img_path', metavar='content', type=str, help='path to content image')\n",
    "  parser.add_argument('style_img_path', metavar='style', type=str, help='path to style image')\n",
    "  parser.add_argument('generated_prefix', metavar='gen_prefix', type=str, help='prefix for generated results')\n",
    "\n",
    "  # optional arguments\n",
    "  parser.add_argument(\"--content_weight\", type=float, default=0.02, required=False, help=\"Content Weight\")\n",
    "  parser.add_argument(\"--style_weight\", type=float, default=1, required=False, help=\"Style Weight\")\n",
    "  parser.add_argument(\"--tv_weight\", type=float, default=1, required=False, help=\"Total Variation Weight\")\n",
    "  parser.add_argument(\"--iter\", type=int, default=10, required=False, help=\"Number of Iteration\")\n",
    "  return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start\n",
    "# parser = build_parser()\n",
    "# # fetch arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# fetch required arguments\n",
    "# content_img_path = args.content_img_path\n",
    "# style_img_path = args.style_img_path\n",
    "# generated_prefix = args.generated_prefix\n",
    "\n",
    "## test for jupyter implementation\n",
    "content_img_path = 'images/content_small.jpg'\n",
    "style_img_path = 'images/style_small.jpg'\n",
    "generated_prefix = ''\n",
    "\n",
    "# # fetch optional arguments\n",
    "# content_weight = args.content_weight\n",
    "# style_weight = args.style_weight\n",
    "# tv_weight = args.tv_weight\n",
    "# iteration = args.iter\n",
    "\n",
    "## test for jupyter implementation\n",
    "content_weight = 0.02\n",
    "style_weight = 1\n",
    "tv_weight = 1\n",
    "iteration = 10\n",
    "\n",
    "width, height = load_img(content_img_path).size\n",
    "# print([width,height])\n",
    "img_height = 500\n",
    "img_width = int(width * img_height / height)\n",
    "\n",
    "# test completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img_path):\n",
    "    \n",
    "  # load image as JpegImageFile\n",
    "  new_img = load_img(img_path)\n",
    "  img = load_img(img_path, target_size = (img_height, img_width))\n",
    "\n",
    "  # convert JpegImageFile into ndarray(a multidimensional, fixed size array object)\n",
    "  img = img_to_array(img)\n",
    "\n",
    "  # reshape 3-dimension img into 4-dimension img (by add a dimension upfront)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "\n",
    "  # preprocess image so as to be compatible for keras\n",
    "  np_img = preprocess_input(img)\n",
    "\n",
    "  return np_img\n",
    "\n",
    "def deprocess_img(np_img):\n",
    "  np_img = np_img.reshape((img_height, img_width, 3))\n",
    "\n",
    "  # add back testing-mean-pixel (due to default manipulation in openCV from Caffe of Keras)\n",
    "  np_img[:, :, 0] += 103.939\n",
    "  np_img[:, :, 1] += 116.779\n",
    "  np_img[:, :, 2] += 123.68\n",
    "\n",
    "  # BGR to RGB(due to default manipulation in openCV from Caffe of Keras)\n",
    "  np_img = np_img[:, :, ::-1]\n",
    "  img = np.clip(np_img, 0, 255).astype('uint8')\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tensor representations of input images and ouput images in (samples, height, width, channels) shape (1, height, width, channel)\n",
    "content_img = K.variable(preprocess_img(content_img_path))\n",
    "style_img = K.variable(preprocess_img(style_img_path))\n",
    "#### test confirms above\n",
    "\n",
    "# initial noise image\n",
    "noise_img = np.random.randint(256, size=(1, img_height, img_width, 3)).astype('float64')\n",
    "# change???\n",
    "generated_img =  K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "# print(\"output\")\n",
    "# print(layer_outputs_dict[model.layers[0].name][1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 util loss functions\n",
    "def content_loss(original, generated):\n",
    "  return(K.sum(K.square(original - generated)))\n",
    "\n",
    "# help method for computing style loss\n",
    "def gram_matrix(input):\n",
    "  # n-dimensions to 2 dimensions\n",
    "  temp = K.permute_dimensions(input,(0,1,2))\n",
    "  # print(\"temp_value\")\n",
    "  # print(K.get_value(temp))\n",
    "  features = K.batch_flatten(temp)\n",
    "  # print(\"features\")\n",
    "  # print(K.get_value(features))\n",
    "  # if features is 3*n, return n*n\n",
    "  return K.dot(K.transpose(features), features)\n",
    "\n",
    "def style_loss(style, generated):\n",
    "  style_gram = gram_matrix(style)\n",
    "  gen_gram = gram_matrix(generated)\n",
    "  nl = 3\n",
    "  nl_size = img_height * img_width\n",
    "  return K.sum(K.square(style_gram-gen_gram))/(4.* (nl ** 2) * (nl_size ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_features_names = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "# generate tensor for 3 images\n",
    "input_tensor = K.concatenate([content_img, style_img, generated_img], axis=0)\n",
    "# initialize the VGG19 model\n",
    "model = VGG19(include_top=False, weights='imagenet', input_tensor = input_tensor)\n",
    "# store layer.name and layer.output in dictionary\n",
    "layer_outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "# combine the above several loss functions together\n",
    "def total_loss(content_img, style_imge, generated_img):\n",
    "  loss = K.variable(value=0.)\n",
    "  # content_loss\n",
    "  content_layer_name = 'block5_conv2'\n",
    "  content_layer_features = layer_outputs_dict[content_layer_name]\n",
    "  content_features = content_layer_features[0,:,:,:]\n",
    "  generated_features = content_layer_features[2,:,:,:]\n",
    "  loss = loss + content_weight * content_loss(content_features, generated_features)\n",
    "\n",
    "  # style_loss\n",
    "  active_layers_count = len(style_features_names)\n",
    "  for layer_name in style_features_names:\n",
    "    style_layer_features = layer_outputs_dict[layer_name]\n",
    "    style_features = style_layer_features[1,:,:,:]\n",
    "    generated_features = style_layer_features[2,:,:,:]\n",
    "    style_loss_of_this_layer = style_loss(style_features, generated_features)\n",
    "    loss = loss + style_weight / active_layers_count * style_loss_of_this_layer\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = total_loss(content_img, style_img, generated_img)\n",
    "# don't know how to get value for this l variable\n",
    "\n",
    "# reference https://github.com/keras-team/keras/blob/master/examples/neural_style_transfer.py\n",
    "\n",
    "# should this line be outside the generated_grad_func or inside?\n",
    "#grads = K.gradient(l, generated_img)\n",
    "\n",
    "# generate data point =>loss function\n",
    "def generated_grad_func(loss, generated_img):\n",
    "  grads = K.gradients(l, generated_img)\n",
    "  outputs = [l]\n",
    "  if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "  else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "  f_outputs = K.function([generated_img], outputs)\n",
    "  return f_outputs\n",
    "\n",
    "f_outputs = generated_grad_func(l, generated_img)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_height, img_width, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_value = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_value = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grads_value = grad_value\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grads_values = np.copy(self.grads_value)\n",
    "        self.loss_value = None\n",
    "        self.grads_value = None\n",
    "        return grads_values\n",
    "\n",
    "name = 'name'\n",
    "i = 3\n",
    "prefix = name + '_at_iteration_%d.png' % i\n",
    "# # input_img_data\n",
    "# save_img(prefix, deprocess_img(noise_img))\n",
    "save_img(prefix, deprocess_img(noise_img))\n",
    "# img.show\n",
    "\n",
    "# a = [[1,2,3,9]]\n",
    "# c = [[4,5,6,8],[0,1,2,3]]\n",
    "\n",
    "# inputs = K.placeholder((2, 3))\n",
    "# print(inputs)\n",
    "# input_transposed = K.transpose(inputs)\n",
    "# print(input_transposed)\n",
    "\n",
    "# t = K.concatenate([a, c], axis=0)\n",
    "# with tf.Session() as sess:\n",
    "#   print(t.eval())\n",
    "  \n",
    "\n",
    "# b = K.variable([a,c])\n",
    "# print(b.shape)\n",
    "# print(K.transpose(0).shape)\n",
    "\n",
    "# var = K.variable([[1, 2, 3], [4, 5, 6]])\n",
    "# K.eval(var)\n",
    "\n",
    "# var_transposed = K.transpose(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  evaluator = Evaluator()\n",
    "  input = preprocess_img(content_img_path)\n",
    "  for i in range(iteration):\n",
    "    print('Iteration', i)\n",
    "    start_time = time.time()\n",
    "    input, min_val, info = fmin_l_bfgs_b(evaluator.loss, input.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss', min_val)\n",
    "    end_time = time.time()\n",
    "    print('interation %d completed in %ds' % (i, end_time-start_time))\n",
    "  return(i)\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
